{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e503ec4d-e97a-4ee0-9110-b8f17dca41e1",
   "metadata": {},
   "source": [
    "# Blend Anything\n",
    "\n",
    "Blend any two LoRA models. They should be from the same base model, but that is not strictly required.\n",
    "\n",
    "This uses a very small amount of VRAM (usually < 4GB for Flux/Qwen models) by streaming the layers and blending each one individually.\n",
    "\n",
    "This can resize the LoRAs while blending them. You can target any arbitrary rank, larger or smaller than the original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a388cc9-992b-44f7-b5dc-9fde9887407a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "from typing import Dict, Iterable, Optional, Tuple, Set, Literal, List, Callable\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98bfbac3-516d-4aff-a205-460f9b6e2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dyn_weights_proportional(\n",
    "    target_total_strength: float = 1.0,\n",
    "    floor: float = 0.02,\n",
    ") :\n",
    "    \"\"\"\n",
    "    w_raw ∝ max(s, floor); then scale so (w1*s1 + w2*s2) == target_total_strength.\n",
    "    If both s1/s2 missing, return (1,1).\n",
    "    \"\"\"\n",
    "    eps = 1e-12\n",
    "    def fn(base: str, s1: Optional[float], s2: Optional[float]) -> Tuple[float, float]:\n",
    "        if (s1 is None and s2 is None):\n",
    "            return (1.0, 1.0)\n",
    "        a = max(floor, s1) if s1 is not None and math.isfinite(s1) else floor\n",
    "        b = max(floor, s2) if s2 is not None and math.isfinite(s2) else floor\n",
    "        denom = a + b\n",
    "        p1 = a / (denom + eps)\n",
    "        p2 = b / (denom + eps)\n",
    "        # predicted combined strength (upper bound)\n",
    "        pred = p1 * (s1 if s1 is not None else 0.0) + p2 * (s2 if s2 is not None else 0.0)\n",
    "        scale = target_total_strength / max(pred, eps)\n",
    "        return (scale * p1, scale * p2)\n",
    "    return fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9666da-a5b2-4699-a683-d8294d03ce0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dyn_weights_softmax(\n",
    "    target_total_strength: float = 1.0,\n",
    "    temperature: float = 1.0,\n",
    "    floor: float = 0.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    w_raw = softmax([s1, s2]/T), with optional floor, then rescale so\n",
    "    w1*s1 + w2*s2 == target_total_strength.\n",
    "    \"\"\"\n",
    "    eps = 1e-12\n",
    "    def fn(base: str, s1: Optional[float], s2: Optional[float]):\n",
    "        # handle missing\n",
    "        x1 = s1 if (s1 is not None and math.isfinite(s1)) else float(\"-inf\")\n",
    "        x2 = s2 if (s2 is not None and math.isfinite(s2)) else float(\"-inf\")\n",
    "        if x1 == float(\"-inf\") and x2 == float(\"-inf\"):\n",
    "            return (1.0, 1.0)\n",
    "        m = max(x1, x2)\n",
    "        t = max(temperature, 1e-8)\n",
    "        e1 = 0.0 if x1 == float(\"-inf\") else math.exp((x1 - m)/t)\n",
    "        e2 = 0.0 if x2 == float(\"-inf\") else math.exp((x2 - m)/t)\n",
    "        Z = e1 + e2 + eps\n",
    "        p1 = e1 / Z\n",
    "        p2 = e2 / Z\n",
    "        if floor > 0:\n",
    "            p1 = max(p1, floor); p2 = max(p2, floor)\n",
    "            s = p1 + p2\n",
    "            p1, p2 = p1/s, p2/s\n",
    "        pred = (p1 * (s1 or 0.0)) + (p2 * (s2 or 0.0))\n",
    "        scale = target_total_strength / max(pred, eps)\n",
    "        return (scale * p1, scale * p2)\n",
    "    return fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3f57d99-0a06-4c3e-9709-eaf849a36fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dyn_weights_powerlaw(\n",
    "    target_total_strength: float = 1.0,\n",
    "    p: float = 0.5,      # 0.0 ~ equal weights, 1.0 ~ proportional, >1.0 ~ extra sharp\n",
    "    floor: float = 0.02,\n",
    "):\n",
    "    eps = 1e-12\n",
    "    def fn(base: str, s1: Optional[float], s2: Optional[float]):\n",
    "        if (s1 is None and s2 is None):\n",
    "            return (1.0, 1.0)\n",
    "        a = max(floor, s1 or 0.0) ** max(p, 0.0)\n",
    "        b = max(floor, s2 or 0.0) ** max(p, 0.0)\n",
    "        denom = a + b + eps\n",
    "        p1 = a / denom\n",
    "        p2 = b / denom\n",
    "        pred = p1 * (s1 or 0.0) + p2 * (s2 or 0.0)\n",
    "        scale = target_total_strength / max(pred, eps)\n",
    "        return (scale * p1, scale * p2)\n",
    "    return fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "666d79eb-b5b5-4b7c-93fd-afa92de74dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dyn_weights_margin_sigmoid(\n",
    "    target_total_strength: float = 1.0,\n",
    "    temperature: float = 1.0,\n",
    "    bias: float = 0.0,     # + favors lora1, - favors lora2\n",
    "    floor: float = 0.02\n",
    "):\n",
    "    \"\"\"\n",
    "    p1 = sigmoid((s1 - s2 + bias)/T), p2 = 1 - p1, then rescale to target.\n",
    "    \"\"\"\n",
    "    import math\n",
    "    eps = 1e-12\n",
    "    def sigm(x): return 1.0 / (1.0 + math.exp(-x))\n",
    "    def fn(base: str, s1: Optional[float], s2: Optional[float]):\n",
    "        if s1 is None and s2 is None:\n",
    "            return (1.0, 1.0)\n",
    "        a = s1 or 0.0\n",
    "        b = s2 or 0.0\n",
    "        p1 = sigm(((a - b) + bias) / max(temperature, 1e-8))\n",
    "        p1 = max(floor, min(1.0 - floor, p1))\n",
    "        p2 = 1.0 - p1\n",
    "        pred = p1*a + p2*b\n",
    "        scale = target_total_strength / max(pred, eps)\n",
    "        return (scale * p1, scale * p2)\n",
    "    return fn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c535125d-a1ed-4115-b6d4-b67a0b146d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "_A = \".lora_A.weight\"\n",
    "_B = \".lora_B.weight\"\n",
    "\n",
    "# ---------- key pairing ----------\n",
    "def _pair_bases(sd: Dict[str, torch.Tensor]) -> Set[str]:\n",
    "    a = {k[:-len(_A)] for k in sd.keys() if k.endswith(_A)}\n",
    "    b = {k[:-len(_B)] for k in sd.keys() if k.endswith(_B)}\n",
    "    return a & b\n",
    "\n",
    "def _iter_bases_union(sd1: Dict[str, torch.Tensor],\n",
    "                      sd2: Optional[Dict[str, torch.Tensor]] = None,\n",
    "                      include_bases: Optional[Iterable[str]] = None) -> Iterable[str]:\n",
    "    bases = _pair_bases(sd1)\n",
    "    if sd2:\n",
    "        bases |= _pair_bases(sd2)\n",
    "    if include_bases is not None:\n",
    "        bases &= set(include_bases)\n",
    "    for base in tqdm(sorted(bases)):\n",
    "        yield base\n",
    "\n",
    "# ---------- norms ----------\n",
    "@torch.no_grad()\n",
    "def _spectral_norm_power(W: torch.Tensor, iters: int = 50) -> float:\n",
    "    # Power iteration (stable, low memory)\n",
    "    m, n = W.shape\n",
    "    device = W.device\n",
    "    if m >= n:\n",
    "        v = torch.randn(n, device=device)\n",
    "        v = v / (v.norm() + 1e-12)\n",
    "        for _ in range(iters):\n",
    "            u = (W @ v);  u = u / (u.norm() + 1e-12)\n",
    "            v = (W.T @ u); v = v / (v.norm() + 1e-12)\n",
    "        val = (u @ (W @ v)).item()\n",
    "    else:\n",
    "        u = torch.randn(m, device=device)\n",
    "        u = u / (u.norm() + 1e-12)\n",
    "        for _ in range(iters):\n",
    "            v = (W.T @ u); v = v / (v.norm() + 1e-12)\n",
    "            u = (W @ v);   u = u / (u.norm() + 1e-12)\n",
    "        val = (u @ (W @ v)).item()\n",
    "    return float(abs(val))\n",
    "\n",
    "# ---------- math helpers ----------\n",
    "@torch.no_grad()\n",
    "def _delta_from_AB(A: torch.Tensor, B: torch.Tensor) -> torch.Tensor:\n",
    "    # A: [r, in], B: [out, r] -> Δ: [out, in]\n",
    "    return B @ A\n",
    "\n",
    "def _best_rank_for(deltaW: torch.Tensor, target_rank: Optional[int]) -> int:\n",
    "    m, n = deltaW.shape\n",
    "    max_r = min(m, n)\n",
    "    if target_rank is None:\n",
    "        return max_r\n",
    "    return max(1, min(int(target_rank), max_r))\n",
    "\n",
    "@torch.no_grad()\n",
    "def _truncated_factorization(\n",
    "    deltaW: torch.Tensor,\n",
    "    target_rank: int,\n",
    "    method: Literal[\"svd\", \"pca_lowrank\"] = \"svd\",\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Factor ΔW (shape [out, in]) into A', B' such that B'@A' ≈ ΔW with original axes.\n",
    "    \"\"\"\n",
    "    r = _best_rank_for(deltaW, target_rank)\n",
    "    if method == \"pca_lowrank\":\n",
    "        q = min(r + 8, min(*deltaW.shape))\n",
    "        U, S, V = torch.pca_lowrank(deltaW, q=q, center=False)\n",
    "        U, S, Vh = U[:, :r], S[:r], V[:, :r].T\n",
    "    else:\n",
    "        U, S, Vh = torch.linalg.svd(deltaW, full_matrices=False)\n",
    "        U, S, Vh = U[:, :r], S[:r], Vh[:r, :]\n",
    "    sroot = torch.sqrt(torch.clamp(S, min=0))\n",
    "    Bp = U * sroot.unsqueeze(0)      # [out, r]\n",
    "    Ap = sroot.unsqueeze(1) * Vh     # [r, in]\n",
    "    return Ap.contiguous(), Bp.contiguous()\n",
    "\n",
    "def _to_dev_dtype(x: torch.Tensor, device: Optional[torch.device], dtype: Optional[torch.dtype]) -> torch.Tensor:\n",
    "    if device is not None:\n",
    "        x = x.to(device, non_blocking=True)\n",
    "    if dtype is not None and x.dtype != dtype:\n",
    "        x = x.to(dtype)\n",
    "    return x\n",
    "\n",
    "def _maybe_empty_cuda():\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "# ---------- per-block weighting utilities ----------\n",
    "# Static rules: list of (prefix, mul_lora1, mul_lora2)\n",
    "BlockRules = List[Tuple[str, float, float]]\n",
    "\n",
    "def _apply_block_rules(base: str, rules: Optional[BlockRules]) -> Tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Return (m1_rule, m2_rule) from the longest matching prefix rule, else (1.0, 1.0).\n",
    "    \"\"\"\n",
    "    if not rules:\n",
    "        return 1.0, 1.0\n",
    "    best = None\n",
    "    best_len = -1\n",
    "    for prefix, m1, m2 in rules:\n",
    "        if base.startswith(prefix) and len(prefix) > best_len:\n",
    "            best = (m1, m2)\n",
    "            best_len = len(prefix)\n",
    "    return best if best is not None else (1.0, 1.0)\n",
    "\n",
    "# Dynamic callback: (base, s1, s2) -> (m1_dyn, m2_dyn)\n",
    "DynWeightFn = Callable[[str, Optional[float], Optional[float]], Tuple[float, float]]\n",
    "\n",
    "def softmax_spectral_weight_fn(temperature: float = 1.0, floor: float = 0.0) -> DynWeightFn:\n",
    "    \"\"\"\n",
    "    Prefer the LoRA with larger spectral norm via softmax:\n",
    "      w_i ∝ exp( (s_i - max(s)) / T )\n",
    "    'floor' lets a missing/zero norm still get a tiny weight if desired.\n",
    "    \"\"\"\n",
    "    import math\n",
    "    def fn(base: str, s1: Optional[float], s2: Optional[float]) -> Tuple[float, float]:\n",
    "        x1 = s1 if (s1 is not None and s1 == s1) else float(\"-inf\")\n",
    "        x2 = s2 if (s2 is not None and s2 == s2) else float(\"-inf\")\n",
    "        m = max(x1, x2)\n",
    "        if m == float(\"-inf\"):  # both missing\n",
    "            return 1.0, 1.0\n",
    "        e1 = math.exp((x1 - m) / max(temperature, 1e-8)) if x1 != float(\"-inf\") else 0.0\n",
    "        e2 = math.exp((x2 - m) / max(temperature, 1e-8)) if x2 != float(\"-inf\") else 0.0\n",
    "        denom = e1 + e2\n",
    "        if denom <= 0:\n",
    "            return 1.0, 1.0\n",
    "        w1 = e1 / denom\n",
    "        w2 = e2 / denom\n",
    "        if floor > 0.0:\n",
    "            # blend toward a minimal non-zero weight\n",
    "            w1 = max(w1, floor); w2 = max(w2, floor)\n",
    "            s = w1 + w2\n",
    "            w1, w2 = w1 / s, w2 / s\n",
    "        return w1, w2\n",
    "    return fn\n",
    "\n",
    "# ---------- main: streaming blend & rank-convert with per-block weights ----------\n",
    "@torch.no_grad()\n",
    "def blend_and_convert_loras_streaming(\n",
    "    lora1: Dict[str, torch.Tensor],\n",
    "    lora2: Optional[Dict[str, torch.Tensor]] = None,\n",
    "    w1: float = 1.0,\n",
    "    w2: float = 1.0,\n",
    "    target_rank: Optional[int] = 32,\n",
    "    compute_device: Optional[str] = None,      # e.g., \"cuda:0\" or \"cpu\"\n",
    "    compute_dtype: Optional[torch.dtype] = torch.float32,\n",
    "    include_bases: Optional[Iterable[str]] = None,\n",
    "    drop_near_zero: bool = True,\n",
    "    zero_tol: float = 1e-12,\n",
    "    factor_method: Literal[\"svd\", \"pca_lowrank\"] = \"svd\",\n",
    "    # NEW: per-block weighting\n",
    "    block_rules: Optional[BlockRules] = None,                  # static prefix multipliers\n",
    "    dynamic_weight_fn: Optional[DynWeightFn] = None,           # e.g., softmax of spectral norms\n",
    "    dyn_norm_iters: int = 40,                                  # iterations for power-iteration\n",
    ") -> Dict[str, torch.Tensor]:\n",
    "    \"\"\"\n",
    "    Streaming LoRA blend/convert with per-block weights.\n",
    "    Order of multipliers per layer:\n",
    "        effective_w1 = w1 * rule_m1 * dyn_m1\n",
    "        effective_w2 = w2 * rule_m2 * dyn_m2\n",
    "    dynamic_weight_fn receives per-layer spectral norms (computed on-the-fly).\n",
    "    \"\"\"\n",
    "    dev = torch.device(compute_device) if compute_device else None\n",
    "    out_sd: Dict[str, torch.Tensor] = {}\n",
    "\n",
    "    for base in _iter_bases_union(lora1, lora2, include_bases):\n",
    "        # --- load A/B (CPU -> compute device)\n",
    "        A1 = lora1.get(base + _A, None)\n",
    "        B1 = lora1.get(base + _B, None)\n",
    "        A2 = lora2.get(base + _A, None) if lora2 else None\n",
    "        B2 = lora2.get(base + _B, None) if lora2 else None\n",
    "\n",
    "        if A1 is None or B1 is None:\n",
    "            d1 = None\n",
    "        else:\n",
    "            A1d = _to_dev_dtype(A1, dev, compute_dtype)\n",
    "            B1d = _to_dev_dtype(B1, dev, compute_dtype)\n",
    "            d1 = _delta_from_AB(A1d, B1d)\n",
    "\n",
    "        if lora2 is not None and A2 is not None and B2 is not None:\n",
    "            A2d = _to_dev_dtype(A2, dev, compute_dtype)\n",
    "            B2d = _to_dev_dtype(B2, dev, compute_dtype)\n",
    "            d2 = _delta_from_AB(A2d, B2d)\n",
    "        else:\n",
    "            d2 = None\n",
    "\n",
    "        # skip if neither present\n",
    "        if d1 is None and d2 is None:\n",
    "            _maybe_empty_cuda()\n",
    "            continue\n",
    "\n",
    "        # --- per-block multipliers\n",
    "        rule_m1, rule_m2 = _apply_block_rules(base, block_rules)\n",
    "\n",
    "        # dynamic weights by spectral norm (computed lazily)\n",
    "        dyn_m1 = dyn_m2 = 1.0\n",
    "        if dynamic_weight_fn is not None:\n",
    "            s1 = _spectral_norm_power(d1, iters=dyn_norm_iters) if d1 is not None else None\n",
    "            s2 = _spectral_norm_power(d2, iters=dyn_norm_iters) if d2 is not None else None\n",
    "            dyn_m1, dyn_m2 = dynamic_weight_fn(base, s1, s2)\n",
    "\n",
    "        eff_w1 = w1 * rule_m1 * dyn_m1\n",
    "        eff_w2 = w2 * rule_m2 * dyn_m2\n",
    "\n",
    "        # --- blend\n",
    "        if d1 is None:\n",
    "            blended = eff_w2 * d2\n",
    "        elif d2 is None:\n",
    "            blended = eff_w1 * d1\n",
    "        else:\n",
    "            blended = eff_w1 * d1 + eff_w2 * d2\n",
    "\n",
    "        # optionally skip tiny layers\n",
    "        if drop_near_zero and blended.abs().max().item() < zero_tol:\n",
    "            del blended, d1, d2\n",
    "            _maybe_empty_cuda()\n",
    "            continue\n",
    "\n",
    "        # --- factorize to target rank and save on CPU\n",
    "        r = _best_rank_for(blended, target_rank)\n",
    "        A_new, B_new = _truncated_factorization(blended, r, method=factor_method)\n",
    "        out_sd[base + _A] = A_new.detach().to(\"cpu\", copy=True)\n",
    "        out_sd[base + _B] = B_new.detach().to(\"cpu\", copy=True)\n",
    "\n",
    "        # cleanup\n",
    "        del A_new, B_new, blended, d1, d2\n",
    "        _maybe_empty_cuda()\n",
    "\n",
    "    return out_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eadc6049-3a6c-40b5-9aab-ae20e0e8bfc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import safetensors.torch\n",
    "\n",
    "lora1 = safetensors.torch.load_file(\"/mnt/models/tensors/loras/qwen_image/nsfw_qwen_bs8_r32_lowlr_000005000.safetensors\")\n",
    "lora2 = safetensors.torch.load_file(\"/mnt/models/tensors/loras/qwen_image/nsfw_qwen_resume_detail_qha.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "747a7faa-4ce9-498a-b859-58f260fa25ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d048f616a0f46a6bcad023da4d98182",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/840 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dyn_fn = softmax_spectral_weight_fn(temperature=0.5, floor=0.05)\n",
    "\n",
    "blend8 = blend_and_convert_loras_streaming(\n",
    "    lora1, \n",
    "    lora2,\n",
    "    w1=1.0, # 0.5, \n",
    "    w2=1.0, # 0.65, \n",
    "    target_rank=32, \n",
    "    compute_device=\"cuda:0\", \n",
    "    compute_dtype=torch.float32,\n",
    "    # factor_method='pca_lowrank',\n",
    "    dynamic_weight_fn=dyn_fn, \n",
    "    dyn_norm_iters=40,\n",
    ")\n",
    "\n",
    "safetensors.torch.save_file(blend8, \"/mnt/models/tensors/loras/qwen_image/nsfw_qwen_blend_5000_qha_softmax_r32.safetensors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cb7625-55f2-42e3-9575-2105ab75d036",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
